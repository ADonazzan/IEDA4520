{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from sklearn.metrics import r2_score\n",
    "import data_ML as ML\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125.7 ],\n",
       "       [100.21],\n",
       "       [ 50.77],\n",
       "       ...,\n",
       "       [227.33],\n",
       "       [193.25],\n",
       "       [199.  ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "df = ML.getdata(True)\n",
    "\n",
    "df_calls = df[df.optionType == 1].drop(columns='optionType')\n",
    "df_american_calls = df_calls[df_calls.method == 1].drop(columns='method')\n",
    "df_american_calls\n",
    "df_american_calls = df_american_calls[df_american_calls.lastPrice > 5]\n",
    "#training and test datasets\n",
    "y = np.asarray(df_american_calls[['lastPrice']])\n",
    "df_american_calls = df_american_calls.drop(columns='lastPrice')\n",
    "df_american_calls\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in range(len(df_american_calls)):\n",
    "    data_tmp = df_american_calls.iloc[line]\n",
    "    data.append(data_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125.7 ],\n",
       "       [100.21],\n",
       "       [ 50.77],\n",
       "       ...,\n",
       "       [227.33],\n",
       "       [193.25],\n",
       "       [199.  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(data)\n",
    "X = data.reshape((data.shape[0], data.shape[1], 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 68521.0625 - val_loss: 52388.3477\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 871us/step - loss: 60931.1133 - val_loss: 50066.0703\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 873us/step - loss: 60013.2227 - val_loss: 48858.5625\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 865us/step - loss: 56240.7461 - val_loss: 47065.3633\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 950us/step - loss: 56699.6328 - val_loss: 46683.0977\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 955us/step - loss: 55788.3945 - val_loss: 46092.4023\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 55213.4727 - val_loss: 45546.2656\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 915us/step - loss: 53629.3945 - val_loss: 44900.6133\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 53332.4648 - val_loss: 43364.7461\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 51610.3828 - val_loss: 41475.8867\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 886us/step - loss: 49297.0430 - val_loss: 39532.4219\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 45441.1953 - val_loss: 37455.5977\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 923us/step - loss: 44366.3438 - val_loss: 34387.4609\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 892us/step - loss: 43367.2227 - val_loss: 31989.2715\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 885us/step - loss: 38303.1914 - val_loss: 29460.2207\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 36615.6172 - val_loss: 27478.1992\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 877us/step - loss: 35638.0039 - val_loss: 28098.7910\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 862us/step - loss: 32854.8711 - val_loss: 24732.2520\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 867us/step - loss: 29385.4863 - val_loss: 23241.6348\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 868us/step - loss: 28592.8438 - val_loss: 24603.1758\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 27581.0742 - val_loss: 20760.5527\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 891us/step - loss: 28007.6230 - val_loss: 23839.5840\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 854us/step - loss: 25410.4824 - val_loss: 18078.0898\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 25303.0137 - val_loss: 17452.8945\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 922us/step - loss: 23618.8496 - val_loss: 18476.6602\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 913us/step - loss: 22707.4824 - val_loss: 14347.2881\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 893us/step - loss: 22851.8320 - val_loss: 14870.5518\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 855us/step - loss: 20153.2012 - val_loss: 12960.9902\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 893us/step - loss: 18911.7305 - val_loss: 19697.5312\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 921us/step - loss: 19875.4160 - val_loss: 12465.6719\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 918us/step - loss: 17542.5137 - val_loss: 11105.5596\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 901us/step - loss: 17534.7969 - val_loss: 13006.0410\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 873us/step - loss: 15585.6338 - val_loss: 9930.0479\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 869us/step - loss: 15572.5547 - val_loss: 9245.7402\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 867us/step - loss: 14807.5635 - val_loss: 11222.0605\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 15539.4404 - val_loss: 8551.7383\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 963us/step - loss: 14640.5156 - val_loss: 8725.5420\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 890us/step - loss: 15209.3145 - val_loss: 8944.7256\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 871us/step - loss: 12080.0918 - val_loss: 7493.1494\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 858us/step - loss: 11781.6963 - val_loss: 7851.9971\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 869us/step - loss: 11259.7178 - val_loss: 8229.3623\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 856us/step - loss: 13563.6855 - val_loss: 6979.5845\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 893us/step - loss: 12313.0488 - val_loss: 8210.1094\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 866us/step - loss: 12009.6777 - val_loss: 6748.4771\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 901us/step - loss: 11856.9424 - val_loss: 7511.5791\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 861us/step - loss: 11689.8057 - val_loss: 7990.7388\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 884us/step - loss: 13669.5889 - val_loss: 10360.2539\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 890us/step - loss: 12437.5488 - val_loss: 9911.8770\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 886us/step - loss: 12575.2822 - val_loss: 6118.1846\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 897us/step - loss: 10859.2871 - val_loss: 5961.9346\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 904us/step - loss: 10566.3721 - val_loss: 6496.3408\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 866us/step - loss: 10551.5537 - val_loss: 5675.9756\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 869us/step - loss: 11210.7314 - val_loss: 5999.2407\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 927us/step - loss: 10158.3145 - val_loss: 7208.7085\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 929us/step - loss: 10348.6016 - val_loss: 5971.1812\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 866us/step - loss: 10894.7012 - val_loss: 6223.8335\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 856us/step - loss: 10169.0986 - val_loss: 5354.8784\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 873us/step - loss: 9700.3076 - val_loss: 6405.6406\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 859us/step - loss: 10419.7891 - val_loss: 5346.3477\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 861us/step - loss: 12572.5869 - val_loss: 8145.1558\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 853us/step - loss: 10884.1416 - val_loss: 5093.2910\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 880us/step - loss: 11991.8662 - val_loss: 5454.7876\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 860us/step - loss: 12217.9248 - val_loss: 5594.2417\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 896us/step - loss: 8890.4873 - val_loss: 5740.8203\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 874us/step - loss: 9981.5283 - val_loss: 5064.2612\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 889us/step - loss: 9905.7471 - val_loss: 6134.1157\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 870us/step - loss: 9654.6807 - val_loss: 5428.7734\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 880us/step - loss: 10403.5684 - val_loss: 6746.2471\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 856us/step - loss: 10732.6074 - val_loss: 5825.0200\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 863us/step - loss: 9902.7354 - val_loss: 4494.6367\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 867us/step - loss: 9941.5098 - val_loss: 6517.1318\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 871us/step - loss: 9510.2861 - val_loss: 4830.5513\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 855us/step - loss: 9473.2988 - val_loss: 5048.2769\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 871us/step - loss: 10604.7793 - val_loss: 4451.0132\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 868us/step - loss: 9454.8994 - val_loss: 5970.1060\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 875us/step - loss: 9145.8398 - val_loss: 4263.8682\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 872us/step - loss: 9826.3867 - val_loss: 4859.0854\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 855us/step - loss: 9494.1777 - val_loss: 5915.1709\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 886us/step - loss: 8823.9668 - val_loss: 4261.9468\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 893us/step - loss: 8356.9043 - val_loss: 5275.6938\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 909us/step - loss: 10705.2861 - val_loss: 4721.7480\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 896us/step - loss: 9828.4258 - val_loss: 7162.3389\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 888us/step - loss: 10102.1582 - val_loss: 4022.1472\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 926us/step - loss: 8415.1035 - val_loss: 3933.8208\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 855us/step - loss: 8221.9189 - val_loss: 5002.1528\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 863us/step - loss: 8682.4854 - val_loss: 6239.8682\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 871us/step - loss: 10449.6855 - val_loss: 5494.8887\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 872us/step - loss: 8295.4561 - val_loss: 3996.8762\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 899us/step - loss: 7827.3247 - val_loss: 4742.3491\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 904us/step - loss: 7491.5498 - val_loss: 6337.4126\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 900us/step - loss: 9377.6729 - val_loss: 3737.5042\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 907us/step - loss: 8970.1357 - val_loss: 4804.2646\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 904us/step - loss: 9894.2578 - val_loss: 3900.6335\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 893us/step - loss: 9010.5654 - val_loss: 4392.4966\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 914us/step - loss: 8411.7129 - val_loss: 3950.1167\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 894us/step - loss: 8970.4287 - val_loss: 3719.6123\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 873us/step - loss: 7997.5591 - val_loss: 4509.6338\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 860us/step - loss: 8871.8389 - val_loss: 6088.5586\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 855us/step - loss: 10599.4980 - val_loss: 4358.6401\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 861us/step - loss: 8298.8145 - val_loss: 3638.2402\n"
     ]
    }
   ],
   "source": [
    "#ANN with four layers, 10 neurons each\n",
    "#activation function: ReLU\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_dim=5, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(X.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(X.shape[1], 1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "# model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2, strides=3))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# # early_stop = EarlyStopping(monitor='val_loss', patience=15, verbose=1)\n",
    "\n",
    "# from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "# sgd = SGD(lr=0.01, momentum=0.9)\n",
    "# rmsprop = RMSprop(lr=0.001)\n",
    "\n",
    "# model.compile(optimizer=rmsprop, loss='mse')\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 440us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[50.415489196777344]</td>\n",
       "      <td>[35.97]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[269.2870178222656]</td>\n",
       "      <td>[258.87]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1239.4378662109375]</td>\n",
       "      <td>[1340.65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[126.57205963134766]</td>\n",
       "      <td>[107.78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[98.05445861816406]</td>\n",
       "      <td>[87.68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>[63.60062026977539]</td>\n",
       "      <td>[53.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>[64.991943359375]</td>\n",
       "      <td>[34.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>[810.6425170898438]</td>\n",
       "      <td>[827.83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>[152.53683471679688]</td>\n",
       "      <td>[154.31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>[231.963134765625]</td>\n",
       "      <td>[265.43]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               prediction       real\n",
       "0    [50.415489196777344]    [35.97]\n",
       "1     [269.2870178222656]   [258.87]\n",
       "2    [1239.4378662109375]  [1340.65]\n",
       "3    [126.57205963134766]   [107.78]\n",
       "4     [98.05445861816406]    [87.68]\n",
       "..                    ...        ...\n",
       "707   [63.60062026977539]     [53.5]\n",
       "708     [64.991943359375]    [34.15]\n",
       "709   [810.6425170898438]   [827.83]\n",
       "710  [152.53683471679688]   [154.31]\n",
       "711    [231.963134765625]   [265.43]\n",
       "\n",
       "[712 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "import pandas as pd\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "db = pd.DataFrame({'prediction':y_pred.tolist(),'real':y_test.tolist()})\n",
    "db\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
